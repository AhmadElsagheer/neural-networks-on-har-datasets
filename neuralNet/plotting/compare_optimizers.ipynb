{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Comparison Between Different Learning Optimizers\n",
    "---\n",
    "\n",
    "### Optimizers in Experiment\n",
    "1. Gradient Descent\n",
    "2. Adagrad\n",
    "3. RMSProp\n",
    "\n",
    "### 1. Load modules and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set path of this notebook to the root directory\n",
    "import os\n",
    "os.chdir(os.path.join(os.getcwd(), '..'))\n",
    "print 'Current working directory', os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data_utils as du\n",
    "import neural_network as nn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# Prepare datasets for processing\n",
    "du.maybe_pickle('train.csv')\n",
    "du.maybe_pickle('test.csv')\n",
    "\n",
    "train_dataset = du.load_dataset('train')\n",
    "test_dataset = du.load_dataset('test')\n",
    "\n",
    "print\n",
    "print 'Train dataset has shape =', train_dataset[0].shape\n",
    "print 'Test dataset has shape =', test_dataset[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Configure Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hidden_dim = (1024, 512, 64)\n",
    "learning_rate = 0.001\n",
    "num_steps = 5000\n",
    "batch_size = 256\n",
    "val_folds = 7    # Only fold 0 will be used (no cross-validation)\n",
    "\n",
    "# Configure the following lines in affine_layer_variables() in layer_utils.py\n",
    "# w_init = tf.truncated_normal([matrix_dim0, matrix_dim1], stddev=0.1)\n",
    "# b_init = tf.truncated_normal([matrix_dim1], stddev=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Prepare Testing Variables and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def run_network(optimizer):\n",
    "    \n",
    "    kf = KFold(n_splits=val_folds)\n",
    "    train_idx, val_idx = kf.split(train_dataset[0]).next()\n",
    "    \n",
    "    \n",
    "    clf = nn.NeuralNetwork(hidden_dim=hidden_dim, optimizer=optimizer, \n",
    "                 learning_rate=learning_rate, num_steps=num_steps,\n",
    "                 batch_size=batch_size)\n",
    "    \n",
    "    train = du.get_batch(train_dataset, indices=train_idx)\n",
    "    val = du.get_batch(train_dataset, indices=val_idx)\n",
    "    \n",
    "    clf.fit(train, val, 'log/opt/' + optimizer + '/')\n",
    "    train_acc = clf.accuracy(train)\n",
    "    val_acc = clf.accuracy(val)\n",
    "\n",
    "    print 'accuracy on train dataset = %.4f' % train_acc\n",
    "    print 'accuracy on validation dataset = %.4f' % val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Run Network for Every Initialization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "optimizers = [ 'GradientDescentOptimizer', 'AdagradOptimizer', 'RMSPropOptimizer']\n",
    "\n",
    "for opt_name in optimizers:\n",
    "    print \"Running \" + opt_name\n",
    "    print \"=================================\"\n",
    "    run_network(opt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def getData(path):\n",
    "    \"\"\"\n",
    "        Returns data from CSV file exported from Tensorboard. The returned data is an np array.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path).iloc[:, 1:].as_matrix()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot loss for all optimizers\n",
    "opt_names = ['Gradient Descent', 'Adagrad', 'RMS Prop']\n",
    "colors = ['#F1653C', '#83FF33', '#0B2D5A']\n",
    "for idx, opt in enumerate(optimizers):\n",
    "    loss_data = getData('plotting/data_csv/opt/loss/' + opt + '.csv')\n",
    "    x, y = loss_data[:, 0], loss_data[:, 1]\n",
    "    plt.plot(x, y, color=colors[idx], label=opt_names[idx], zorder=-idx)\n",
    "plt.title('Loss Function for Optimizers')\n",
    "plt.legend()\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('loss')\n",
    "plt.axis([0, 5000, 0, 1.5])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot val accuracies for all optimizers\n",
    "opt_names = ['Gradient Descent', 'Adagrad', 'RMS Prop']\n",
    "colors = ['#F1653C', '#83FF33', '#0B2D5A']\n",
    "for idx, opt in enumerate(optimizers):\n",
    "    val_data = getData('plotting/data_csv/opt/val_acc/' + opt + '.csv')\n",
    "    x, y = val_data[:, 0], val_data[:, 1]\n",
    "    plt.plot(x, y, color=colors[idx], label=opt_names[idx], zorder=-idx)\n",
    "plt.title('Validation Accuracy for Optimizers')\n",
    "plt.legend(bbox_to_anchor=(0., .12, 1., .102))\n",
    "\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.axis([0, 5000, 0.5, 1])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For best optimizer plot train accuracy vs validation accuracy\n",
    "# Plot val accuracies for all optimizers\n",
    "opt = 'RMSPropOptimizer'\n",
    "opt_name = 'RMS Prop'\n",
    "train_data = getData('plotting/data_csv/opt/train_acc/' + opt + '.csv')\n",
    "val_data = getData('plotting/data_csv/opt/val_acc/' + opt + '.csv')\n",
    "\n",
    "x1, y1 = train_data[:, 0], train_data[:, 1]\n",
    "x2, y2 = val_data[:, 0], val_data[:, 1]\n",
    "plt.plot(x1, y1, color='#CD2626', label='Training')\n",
    "plt.plot(x2, y2, color='#08B200', label='Validation')\n",
    "plt.title('Training vs Validation Accuracies for ' + opt_name)\n",
    "plt.legend(bbox_to_anchor=(0., .12, 1., .102))\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('accuracy')\n",
    "plt.axis([0, 5000, 0.5, 1.01])\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
