{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Comparison Between Different Initialization Methods\n",
    "---\n",
    "\n",
    "### Methods in Experiment\n",
    "1. weights and biases: truncated Normal Distribution with std = 0.1\n",
    "2. weights: truncated Normal Distribution with std = 0.1, biases: 0\n",
    "3. weights: truncated Normal Distribution with std = 0.01, biases: 0\n",
    "4. weights: truncated Normal Distribution with std = 0.1 divided by sqrt(fan_in/2), biases: 0\n",
    "5. weights: truncated Normal Distribution with std = 0.1 divided by sqrt(fan_in/2), biases: 0\n",
    "\n",
    "### 1. Load modules and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set path of this notebook to the root directory\n",
    "import os\n",
    "os.chdir(os.path.join(os.getcwd(), '..'))\n",
    "print 'Current working directory', os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For auto-reloading external modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import data_utils as du\n",
    "import neural_network as nn\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "# Prepare datasets for processing\n",
    "du.maybe_pickle('train.csv')\n",
    "du.maybe_pickle('test.csv')\n",
    "\n",
    "train_dataset = du.load_dataset('train')\n",
    "test_dataset = du.load_dataset('test')\n",
    "\n",
    "print\n",
    "print 'Train dataset has shape =', train_dataset[0].shape\n",
    "print 'Test dataset has shape =', test_dataset[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 2. Configure Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hidden_dim = (1024, 512, 64)\n",
    "learning_rate = 0.001\n",
    "num_steps = 5000\n",
    "batch_size = 256\n",
    "optimizer = 'RMSPropOptimizer'\n",
    "val_folds = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 3. Prepare Testing Variables and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Collect val accuracies for all method to plot them\n",
    "methods_val_accs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "def run_network(method_name):\n",
    "    \n",
    "    kf = KFold(n_splits=val_folds)\n",
    "    train_accs, val_accs = [], []\n",
    "    itr_num = 0\n",
    "    for train_idx, val_idx in kf.split(train_dataset[0]):\n",
    "        while(True):\n",
    "            clf = nn.NeuralNetwork(hidden_dim=hidden_dim, optimizer=optimizer, \n",
    "                         learning_rate=learning_rate, num_steps=num_steps,\n",
    "                         batch_size=batch_size)\n",
    "            itr_train = du.get_batch(train_dataset, indices=train_idx)\n",
    "            itr_val = du.get_batch(train_dataset, indices=val_idx)\n",
    "\n",
    "            clf.fit(itr_train, itr_val, 'log/init/' + method_name + '/' + str(itr_num) + '/')\n",
    "            itr_train_acc = clf.accuracy(itr_train)\n",
    "            itr_val_acc = clf.accuracy(itr_val)\n",
    "            if(itr_train_acc < 0.98):\n",
    "                shutil.rmtree('log/init/' + method_name + '/' + str(itr_num) + '/')\n",
    "                continue\n",
    "            itr_num += 1\n",
    "\n",
    "            print 'Iteration %d\\n============' % itr_num\n",
    "\n",
    "            train_accs.append(itr_train_acc)\n",
    "            print 'accuracy on train dataset = %.4f' % itr_train_acc\n",
    "\n",
    "\n",
    "            val_accs.append(itr_val_acc)\n",
    "            print 'accuracy on validation dataset = %.4f' % itr_val_acc\n",
    "\n",
    "            print\n",
    "            \n",
    "            break\n",
    "\n",
    "    train_acc = np.mean(train_accs)\n",
    "    print 'average accuracy on train dataset = %.4f' % train_acc\n",
    "\n",
    "    val_acc = np.mean(val_accs)\n",
    "    print 'average accuracy on validation dataset = %.4f' % val_acc\n",
    "    \n",
    "    methods_val_accs.append(val_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 4. Run Network for Every Initialization Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running network for Method 1\n",
    "\n",
    "# Manual Modification: Set the following in affine_layer_variables() in layer_utils.py:\n",
    "# w_init = tf.truncated_normal([matrix_dim0, matrix_dim1], stddev=0.1)\n",
    "# b_init = tf.truncated_normal([matrix_dim1], stddev=0.1)\n",
    "\n",
    "run_network('method1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running network for Method 2\n",
    "\n",
    "# Manual Modification: Set the following in affine_layer_variables() in layer_utils.py:\n",
    "# w_init = tf.truncated_normal([matrix_dim0, matrix_dim1], stddev=0.1)\n",
    "# b_init = tf.zeros([matrix_dim1])\n",
    "\n",
    "run_network('method2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running network for Method 3\n",
    "\n",
    "# Manual Modification: Set the following in affine_layer_variables() in layer_utils.py:\n",
    "# w_init = tf.truncated_normal([matrix_dim0, matrix_dim1], stddev=0.01)\n",
    "# b_init = tf.zeros([matrix_dim1])\n",
    "\n",
    "run_network('method3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running network for Method 4\n",
    "\n",
    "# Manual Modification: Set the following in affine_layer_variables() in layer_utils.py:\n",
    "# w_init = tf.divide(tf.truncated_normal([matrix_dim0, matrix_dim1], stddev=0.01), tf.sqrt(matrix_dim0 / 2.0))\n",
    "# b_init = tf.zeros([matrix_dim1])\n",
    "\n",
    "run_network('method4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Running network for Method 5\n",
    "\n",
    "# Manual Modification: Set the following in affine_layer_variables() in layer_utils.py:\n",
    "# w_init = tf.divide(tf.truncated_normal([matrix_dim0, matrix_dim1], stddev=0.1), tf.sqrt(matrix_dim0 / 2.0))\n",
    "# b_init = tf.zeros([matrix_dim1])\n",
    "\n",
    "run_network('method5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for val_accs in methods_val_accs:\n",
    "    print val_accs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 5. Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def getData(path):\n",
    "    \"\"\"\n",
    "        Returns data from CSV file exported from Tensorboard. The returned data is an np array.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(path).iloc[:, 1:].as_matrix()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Plot cross-validation accuracies with std for all methods\n",
    "accs = methods_val_accs\n",
    "acc_mean = np.array([np.mean(v) for v in accs])\n",
    "acc_std = np.array([np.std(v) for v in accs])\n",
    "\n",
    "for method_idx, acc in enumerate(accs):\n",
    "    plt.scatter([method_idx + 1] * len(accs[method_idx]), accs[method_idx], color='red')\n",
    "plt.errorbar(range(1, len(accs) + 1), acc_mean, yerr=acc_std, color='green', ecolor='orange')\n",
    "plt.title('Cross-validation on Initialization Method')\n",
    "plt.xlabel('Method Index')\n",
    "plt.ylabel('Cross-validation accuracy')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For best method, plot train accuracy vs val accuracy (for a single iteration)\n",
    "train_data = getData('plotting/data_csv/init/best_train_acc.csv')\n",
    "val_data = getData('plotting/data_csv/init/best_val_acc.csv')\n",
    "\n",
    "x1, y1 = train_data[:, 0], train_data[:, 1]\n",
    "x2, y2 = val_data[:, 0], val_data[:, 1]\n",
    "\n",
    "plt.plot(x1, y1, color='#FF5733', label='Train')\n",
    "plt.plot(x2, y2, color='#83FF33', label='Validation')\n",
    "plt.legend()\n",
    "plt.axis([0, 5000, 0.8, 1.1])\n",
    "plt.xlabel('steps')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# For best method, plot a histogram for weights of layers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
